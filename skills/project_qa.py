#!/usr/bin/env python3
"""
AI é©±åŠ¨çš„é¡¹ç›®é—®ç­” Skill

åŠŸèƒ½ï¼š
1. åˆ†æé¡¹ç›®ç»“æ„å’Œä»£ç 
2. å›ç­”å…³äºé¡¹ç›®çš„é—®é¢˜
3. æä¾›æ™ºèƒ½å»ºè®®å’Œæ´å¯Ÿ
"""

import sys
import json
from pathlib import Path
from typing import Dict, Any, List, Optional

# æ·»åŠ çˆ¶ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from src.analyzers import (
    ProjectAnalyzer,
    CodeQualityAnalyzer,
    DependencyAnalyzer,
    MetricsCollector
)


class ProjectQASkill:
    """é¡¹ç›®é—®ç­” Skill"""

    def __init__(self, project_path: Path):
        """
        åˆå§‹åŒ– Skill

        Args:
            project_path: é¡¹ç›®è·¯å¾„
        """
        self.project_path = Path(project_path)
        self.context = {}
        self._analyze_project()

    def _analyze_project(self):
        """åˆ†æé¡¹ç›®å¹¶æ„å»ºä¸Šä¸‹æ–‡"""
        print("ğŸ” æ­£åœ¨åˆ†æé¡¹ç›®...")

        # æ”¶é›†é¡¹ç›®ä¿¡æ¯
        collector = MetricsCollector(self.project_path)
        result = collector.analyze()

        self.context = {
            'project_name': self.project_path.name,
            'project_path': str(self.project_path),
            'analysis_result': result.data,
            'errors': result.errors,
            'warnings': result.warnings,
        }

        print("âœ… é¡¹ç›®åˆ†æå®Œæˆ\n")

    def ask(self, question: str) -> Dict[str, Any]:
        """
        å›ç­”å…³äºé¡¹ç›®çš„é—®é¢˜

        Args:
            question: ç”¨æˆ·é—®é¢˜

        Returns:
            Dict: åŒ…å«ç­”æ¡ˆå’Œç›¸å…³ä¿¡æ¯
        """
        # è¯†åˆ«é—®é¢˜ç±»å‹
        question_type = self._classify_question(question)

        # æ ¹æ®é—®é¢˜ç±»å‹ç”Ÿæˆç­”æ¡ˆ
        if question_type == 'structure':
            return self._answer_structure_question(question)
        elif question_type == 'quality':
            return self._answer_quality_question(question)
        elif question_type == 'dependency':
            return self._answer_dependency_question(question)
        elif question_type == 'score':
            return self._answer_score_question(question)
        elif question_type == 'files':
            return self._answer_files_question(question)
        elif question_type == 'improvement':
            return self._answer_improvement_question(question)
        else:
            return self._answer_general_question(question)

    def _classify_question(self, question: str) -> str:
        """åˆ†ç±»é—®é¢˜ç±»å‹"""
        question_lower = question.lower()

        # å…³é”®è¯æ˜ å°„
        keywords = {
            'structure': ['ç»“æ„', 'ç›®å½•', 'æ–‡ä»¶', 'ç»„ç»‡', 'structure', 'directory', 'file'],
            'quality': ['è´¨é‡', 'å¤æ‚åº¦', 'é£æ ¼', 'quality', 'complexity', 'style'],
            'dependency': ['ä¾èµ–', 'åŒ…', 'åº“', 'dependency', 'package', 'library'],
            'score': ['è¯„åˆ†', 'åˆ†æ•°', 'ç­‰çº§', 'score', 'grade', 'rating'],
            'files': ['æœ‰å“ªäº›', 'åŒ…å«', 'åˆ—å‡º', 'list', 'show', 'what'],
            'improvement': ['æ”¹è¿›', 'ä¼˜åŒ–', 'å»ºè®®', 'improve', 'optimize', 'suggest'],
        }

        for qtype, words in keywords.items():
            if any(word in question_lower for word in words):
                return qtype

        return 'general'

    def _answer_structure_question(self, question: str) -> Dict[str, Any]:
        """å›ç­”ç»“æ„ç›¸å…³é—®é¢˜"""
        project_data = self.context['analysis_result']['project']

        answer = {
            'question': question,
            'type': 'structure',
            'answer': self._format_structure_answer(project_data),
            'details': {
                'total_files': project_data['file_structure']['total_files'],
                'file_types': project_data['file_type_distribution'],
                'project_size': project_data['project_info']['size'],
            }
        }

        return answer

    def _format_structure_answer(self, project_data: Dict) -> str:
        """æ ¼å¼åŒ–ç»“æ„ç­”æ¡ˆ"""
        info = project_data['project_info']
        structure = project_data['file_structure']
        file_types = project_data['file_type_distribution']

        answer = f"""
ğŸ“ é¡¹ç›®ç»“æ„åˆ†æï¼š

**åŸºæœ¬ä¿¡æ¯**
- é¡¹ç›®åç§°: {info['name']}
- é¡¹ç›®ç±»å‹: {', '.join(info['project_type'])}
- é¡¹ç›®å¤§å°: {info['size']}
- æ€»æ–‡ä»¶æ•°: {structure['total_files']}

**æ–‡ä»¶ç±»å‹åˆ†å¸ƒ** (å‰5ç§)
"""
        for ext, count in list(file_types.items())[:5]:
            answer += f"- .{ext}: {count} ä¸ªæ–‡ä»¶\n"

        if info.get('is_git_repo'):
            git_info = info.get('git_info', {})
            answer += f"\n**Git ä¿¡æ¯**\n"
            answer += f"- å½“å‰åˆ†æ”¯: {git_info.get('current_branch', 'N/A')}\n"

        return answer.strip()

    def _answer_quality_question(self, question: str) -> Dict[str, Any]:
        """å›ç­”è´¨é‡ç›¸å…³é—®é¢˜"""
        quality_data = self.context['analysis_result']['quality']

        answer = {
            'question': question,
            'type': 'quality',
            'answer': self._format_quality_answer(quality_data),
            'details': quality_data
        }

        return answer

    def _format_quality_answer(self, quality_data: Dict) -> str:
        """æ ¼å¼åŒ–è´¨é‡ç­”æ¡ˆ"""
        python_analysis = quality_data.get('python_analysis', {})
        complexity = quality_data.get('complexity_analysis', {})
        style_issues = quality_data.get('style_issues', {})
        best_practices = quality_data.get('best_practices', {})

        answer = f"""
ğŸ“Š ä»£ç è´¨é‡åˆ†æï¼š

**Python ä»£ç ç»Ÿè®¡**
- æ€»å‡½æ•°æ•°: {python_analysis.get('total_functions', 0)}
- æ€»ç±»æ•°: {python_analysis.get('total_classes', 0)}
- å¹³å‡å‡½æ•°é•¿åº¦: {python_analysis.get('average_function_length', 0)} è¡Œ

**å¤æ‚åº¦åˆ†æ**
- å¹³å‡å¤æ‚åº¦: {complexity.get('average_complexity', 0)}
- æœ€å¤§å¤æ‚åº¦: {complexity.get('max_complexity', 0)}
"""

        high_complexity = complexity.get('high_complexity_functions', [])
        if high_complexity:
            answer += f"\nâš ï¸ å‘ç° {len(high_complexity)} ä¸ªé«˜å¤æ‚åº¦å‡½æ•°\n"

        answer += f"""
**ä»£ç é£æ ¼**
- æ€»é—®é¢˜æ•°: {style_issues.get('total_issues', 0)}

**æœ€ä½³å®è·µ**
- {'âœ…' if best_practices.get('has_tests') else 'âŒ'} æµ‹è¯•ç”¨ä¾‹
- {'âœ…' if best_practices.get('has_readme') else 'âŒ'} README æ–‡æ¡£
- {'âœ…' if best_practices.get('has_requirements') else 'âŒ'} ä¾èµ–ç®¡ç†
- {'âœ…' if best_practices.get('has_gitignore') else 'âŒ'} .gitignore
- {'âœ…' if best_practices.get('has_license') else 'âŒ'} å¼€æºè®¸å¯è¯
"""

        return answer.strip()

    def _answer_dependency_question(self, question: str) -> Dict[str, Any]:
        """å›ç­”ä¾èµ–ç›¸å…³é—®é¢˜"""
        dep_data = self.context['analysis_result']['dependencies']

        answer = {
            'question': question,
            'type': 'dependency',
            'answer': self._format_dependency_answer(dep_data),
            'details': dep_data
        }

        return answer

    def _format_dependency_answer(self, dep_data: Dict) -> str:
        """æ ¼å¼åŒ–ä¾èµ–ç­”æ¡ˆ"""
        python_deps = dep_data.get('python_dependencies', {})
        nodejs_deps = dep_data.get('nodejs_dependencies', {})
        version_analysis = dep_data.get('version_analysis', {})

        answer = "ğŸ“¦ ä¾èµ–åˆ†æï¼š\n\n"

        if python_deps.get('found'):
            answer += f"**Python ä¾èµ–** ({python_deps.get('source', 'N/A')})\n"
            answer += f"- æ€»åŒ…æ•°: {python_deps.get('total_count', 0)}\n"

            packages = python_deps.get('packages', [])
            if packages:
                answer += "\nä¸»è¦ä¾èµ–:\n"
                for pkg in packages[:10]:
                    answer += f"- {pkg['name']} {pkg.get('version_spec', '')}\n"

        if nodejs_deps.get('found'):
            answer += f"\n**Node.js ä¾èµ–**\n"
            answer += f"- æ€»åŒ…æ•°: {nodejs_deps.get('total_count', 0)}\n"

        if version_analysis:
            answer += f"\n**ç‰ˆæœ¬ç®¡ç†**\n"
            answer += f"- å›ºå®šç‰ˆæœ¬: {version_analysis.get('pinned_versions', 0)}\n"
            answer += f"- çµæ´»ç‰ˆæœ¬: {version_analysis.get('flexible_versions', 0)}\n"
            answer += f"- æœªæŒ‡å®šç‰ˆæœ¬: {version_analysis.get('latest_versions', 0)}\n"

        return answer.strip()

    def _answer_score_question(self, question: str) -> Dict[str, Any]:
        """å›ç­”è¯„åˆ†ç›¸å…³é—®é¢˜"""
        score = self.context['analysis_result']['overall_score']
        summary = self.context['analysis_result']['summary']

        answer = {
            'question': question,
            'type': 'score',
            'answer': self._format_score_answer(score, summary),
            'details': {'score': score, 'summary': summary}
        }

        return answer

    def _format_score_answer(self, score: Dict, summary: Dict) -> str:
        """æ ¼å¼åŒ–è¯„åˆ†ç­”æ¡ˆ"""
        answer = f"""
ğŸ¯ é¡¹ç›®è¯„åˆ†ï¼š

**ç»¼åˆè¯„åˆ†**: {score['total']}/100 ({score['grade']})

**è¯„åˆ†ç»†åˆ†**
"""
        for category, points in score['breakdown'].items():
            answer += f"- {category}: {points}åˆ†\n"

        if summary.get('highlights'):
            answer += "\n**âœ… äº®ç‚¹**\n"
            for highlight in summary['highlights']:
                answer += f"- {highlight}\n"

        if summary.get('concerns'):
            answer += "\n**âš ï¸ éœ€è¦å…³æ³¨**\n"
            for concern in summary['concerns']:
                answer += f"- {concern}\n"

        return answer.strip()

    def _answer_files_question(self, question: str) -> Dict[str, Any]:
        """å›ç­”æ–‡ä»¶åˆ—è¡¨ç›¸å…³é—®é¢˜"""
        project_data = self.context['analysis_result']['project']

        # æ ¹æ®é—®é¢˜æå–æ–‡ä»¶ç±»å‹
        file_type = self._extract_file_type(question)

        if file_type:
            files = self._get_files_by_type(file_type)
            answer_text = f"é¡¹ç›®ä¸­çš„ {file_type} æ–‡ä»¶ï¼š\n\n"
            for f in files[:20]:
                answer_text += f"- {f}\n"
            if len(files) > 20:
                answer_text += f"\n... è¿˜æœ‰ {len(files) - 20} ä¸ªæ–‡ä»¶"
        else:
            file_list = project_data['file_structure'].get('file_list', [])
            answer_text = f"é¡¹ç›®æ–‡ä»¶åˆ—è¡¨ï¼ˆå‰20ä¸ªï¼‰ï¼š\n\n"
            for f in file_list[:20]:
                answer_text += f"- {f}\n"

        answer = {
            'question': question,
            'type': 'files',
            'answer': answer_text.strip(),
            'details': {}
        }

        return answer

    def _extract_file_type(self, question: str) -> Optional[str]:
        """ä»é—®é¢˜ä¸­æå–æ–‡ä»¶ç±»å‹"""
        extensions = ['.py', '.js', '.ts', '.md', '.html', '.css', '.json', '.yaml', '.yml']
        for ext in extensions:
            if ext in question.lower():
                return ext
        return None

    def _get_files_by_type(self, file_type: str) -> List[str]:
        """è·å–æŒ‡å®šç±»å‹çš„æ–‡ä»¶"""
        from src.analyzers import ProjectAnalyzer

        analyzer = ProjectAnalyzer(self.project_path)
        files = analyzer._scan_files(pattern=f"*{file_type}")
        return [str(f.relative_to(self.project_path)) for f in files]

    def _answer_improvement_question(self, question: str) -> Dict[str, Any]:
        """å›ç­”æ”¹è¿›å»ºè®®ç›¸å…³é—®é¢˜"""
        quality_data = self.context['analysis_result']['quality']
        best_practices = quality_data.get('best_practices', {})
        recommendations = best_practices.get('recommendations', [])

        answer_text = "ğŸ’¡ æ”¹è¿›å»ºè®®ï¼š\n\n"

        if recommendations:
            for i, rec in enumerate(recommendations, 1):
                answer_text += f"{i}. {rec}\n"
        else:
            answer_text += "é¡¹ç›®æ•´ä½“çŠ¶å†µè‰¯å¥½ï¼Œæš‚æ— é‡è¦æ”¹è¿›å»ºè®®ã€‚\n"

        # æ·»åŠ åŸºäºè¯„åˆ†çš„å»ºè®®
        score = self.context['analysis_result']['overall_score']
        if score['total'] < 60:
            answer_text += "\n**ä¼˜å…ˆæ”¹è¿›é¡¹**\n"
            answer_text += "- é¡¹ç›®è¯„åˆ†è¾ƒä½ï¼Œå»ºè®®ä¼˜å…ˆå…³æ³¨ä»£ç è´¨é‡å’Œæœ€ä½³å®è·µ\n"

        complexity = quality_data.get('complexity_analysis', {})
        if complexity.get('max_complexity', 0) > 15:
            answer_text += "- é™ä½é«˜å¤æ‚åº¦å‡½æ•°çš„å¤æ‚åº¦\n"

        answer = {
            'question': question,
            'type': 'improvement',
            'answer': answer_text.strip(),
            'details': {'recommendations': recommendations}
        }

        return answer

    def _answer_general_question(self, question: str) -> Dict[str, Any]:
        """å›ç­”ä¸€èˆ¬æ€§é—®é¢˜"""
        # æä¾›é¡¹ç›®æ¦‚è§ˆ
        summary = self.context['analysis_result']['summary']
        score = self.context['analysis_result']['overall_score']

        answer_text = f"""
å…³äºé¡¹ç›® "{self.context['project_name']}" çš„ä¿¡æ¯ï¼š

**é¡¹ç›®æ¦‚è§ˆ**
- è¯„åˆ†: {score['total']}/100 ({score['grade']})
- æ€»æ–‡ä»¶æ•°: {summary['key_metrics']['total_files']}
- ä»£ç è¡Œæ•°: {summary['key_metrics']['code_lines']}
- å‡½æ•°æ•°é‡: {summary['key_metrics']['total_functions']}
- ç±»æ•°é‡: {summary['key_metrics']['total_classes']}

æ‚¨å¯ä»¥é—®æˆ‘ï¼š
- é¡¹ç›®ç»“æ„å¦‚ä½•ï¼Ÿ
- ä»£ç è´¨é‡æ€ä¹ˆæ ·ï¼Ÿ
- æœ‰å“ªäº›ä¾èµ–ï¼Ÿ
- é¡¹ç›®è¯„åˆ†æ˜¯å¤šå°‘ï¼Ÿ
- æœ‰ä»€ä¹ˆæ”¹è¿›å»ºè®®ï¼Ÿ
- é¡¹ç›®ä¸­æœ‰å“ªäº› Python æ–‡ä»¶ï¼Ÿ
"""

        answer = {
            'question': question,
            'type': 'general',
            'answer': answer_text.strip(),
            'details': summary
        }

        return answer

    def interactive_mode(self):
        """äº¤äº’å¼é—®ç­”æ¨¡å¼"""
        print(f"\n{'='*60}")
        print(f"ğŸ¤– AI é¡¹ç›®åˆ†æåŠ©æ‰‹")
        print(f"{'='*60}")
        print(f"é¡¹ç›®: {self.context['project_name']}")
        print(f"è·¯å¾„: {self.context['project_path']}")
        print(f"è¯„åˆ†: {self.context['analysis_result']['overall_score']['total']}/100")
        print(f"{'='*60}\n")
        print("ğŸ’¡ æç¤º: è¾“å…¥ 'quit' æˆ– 'exit' é€€å‡º\n")

        while True:
            try:
                question = input("â“ æ‚¨çš„é—®é¢˜: ").strip()

                if not question:
                    continue

                if question.lower() in ['quit', 'exit', 'q']:
                    print("\nğŸ‘‹ å†è§ï¼")
                    break

                # å›ç­”é—®é¢˜
                result = self.ask(question)

                print(f"\nğŸ’¬ å›ç­”:\n")
                print(result['answer'])
                print(f"\n{'-'*60}\n")

            except KeyboardInterrupt:
                print("\n\nğŸ‘‹ å†è§ï¼")
                break
            except Exception as e:
                print(f"\nâŒ é”™è¯¯: {str(e)}\n")


def main():
    """ä¸»å‡½æ•°"""
    import argparse

    parser = argparse.ArgumentParser(
        description='AI é©±åŠ¨çš„é¡¹ç›®é—®ç­” Skill',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # äº¤äº’å¼æ¨¡å¼
  python project_qa.py /path/to/project

  # å•ä¸ªé—®é¢˜
  python project_qa.py /path/to/project -q "é¡¹ç›®ç»“æ„å¦‚ä½•ï¼Ÿ"

  # JSON è¾“å‡º
  python project_qa.py /path/to/project -q "ä»£ç è´¨é‡æ€ä¹ˆæ ·ï¼Ÿ" --json
        """
    )

    parser.add_argument(
        'project_path',
        help='é¡¹ç›®è·¯å¾„'
    )

    parser.add_argument(
        '-q', '--question',
        help='è¦é—®çš„é—®é¢˜ï¼ˆä¸æŒ‡å®šåˆ™è¿›å…¥äº¤äº’æ¨¡å¼ï¼‰'
    )

    parser.add_argument(
        '--json',
        action='store_true',
        help='ä»¥ JSON æ ¼å¼è¾“å‡º'
    )

    args = parser.parse_args()

    # éªŒè¯é¡¹ç›®è·¯å¾„
    project_path = Path(args.project_path)
    if not project_path.exists():
        print(f"âŒ é”™è¯¯: é¡¹ç›®è·¯å¾„ä¸å­˜åœ¨: {project_path}")
        return 1

    # åˆå§‹åŒ– Skill
    skill = ProjectQASkill(project_path)

    # å•ä¸ªé—®é¢˜æ¨¡å¼
    if args.question:
        result = skill.ask(args.question)

        if args.json:
            print(json.dumps(result, indent=2, ensure_ascii=False))
        else:
            print(f"\nâ“ é—®é¢˜: {result['question']}\n")
            print(f"ğŸ’¬ å›ç­”:\n")
            print(result['answer'])

        return 0

    # äº¤äº’å¼æ¨¡å¼
    skill.interactive_mode()

    return 0


if __name__ == '__main__':
    sys.exit(main())
