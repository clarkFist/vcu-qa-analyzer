#!/usr/bin/env python3
"""
AI é©±åŠ¨çš„æ™ºèƒ½ä»£ç æ´å¯Ÿ Skill

åŠŸèƒ½ï¼š
1. æ·±åº¦ä»£ç åˆ†æ
2. æ¶æ„æ¨¡å¼è¯†åˆ«
3. æ½œåœ¨é—®é¢˜æ£€æµ‹
4. é‡æ„å»ºè®®
"""

import sys
import ast
import json
from pathlib import Path
from typing import Dict, Any, List, Set
from collections import defaultdict

# æ·»åŠ çˆ¶ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from src.analyzers.base import BaseAnalyzer


class CodeInsightSkill:
    """æ™ºèƒ½ä»£ç æ´å¯Ÿ Skill"""

    def __init__(self, project_path: Path):
        """åˆå§‹åŒ– Skill"""
        self.project_path = Path(project_path)
        self.insights = {}
        self._analyze_code()

    def _analyze_code(self):
        """æ·±åº¦ä»£ç åˆ†æ"""
        print("ğŸ” æ­£åœ¨è¿›è¡Œæ·±åº¦ä»£ç åˆ†æ...")

        # ä½¿ç”¨ ProjectAnalyzer æ¥æ‰«ææ–‡ä»¶
        from src.analyzers import ProjectAnalyzer
        analyzer = ProjectAnalyzer(self.project_path)
        python_files = analyzer._scan_files(pattern="*.py")

        self.insights = {
            'architecture_patterns': self._detect_architecture_patterns(python_files),
            'code_smells': self._detect_code_smells(python_files),
            'import_graph': self._build_import_graph(python_files),
            'function_analysis': self._analyze_functions(python_files),
            'class_hierarchy': self._analyze_class_hierarchy(python_files),
        }

        print("âœ… æ·±åº¦åˆ†æå®Œæˆ\n")

    def _detect_architecture_patterns(self, python_files: List[Path]) -> Dict[str, Any]:
        """æ£€æµ‹æ¶æ„æ¨¡å¼"""
        patterns = {
            'mvc': False,
            'mvvm': False,
            'layered': False,
            'microservices': False,
            'detected_patterns': []
        }

        # æ£€æŸ¥ç›®å½•ç»“æ„
        dirs = set()
        for file in python_files:
            parts = file.relative_to(self.project_path).parts
            if len(parts) > 1:
                dirs.add(parts[0])

        # MVC æ¨¡å¼æ£€æµ‹
        mvc_keywords = {'models', 'views', 'controllers'}
        if mvc_keywords.issubset(dirs):
            patterns['mvc'] = True
            patterns['detected_patterns'].append('MVC (Model-View-Controller)')

        # åˆ†å±‚æ¶æ„æ£€æµ‹
        layered_keywords = {'api', 'service', 'repository', 'domain'}
        if len(layered_keywords.intersection(dirs)) >= 2:
            patterns['layered'] = True
            patterns['detected_patterns'].append('Layered Architecture')

        # å¾®æœåŠ¡æ£€æµ‹
        if 'services' in dirs or 'microservices' in dirs:
            patterns['microservices'] = True
            patterns['detected_patterns'].append('Microservices')

        return patterns

    def _detect_code_smells(self, python_files: List[Path]) -> List[Dict[str, Any]]:
        """æ£€æµ‹ä»£ç å¼‚å‘³"""
        smells = []

        for file_path in python_files[:20]:  # é™åˆ¶åˆ†ææ–‡ä»¶æ•°
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()

                tree = ast.parse(content)
                relative_path = str(file_path.relative_to(self.project_path))

                # æ£€æµ‹é•¿æ–¹æ³•
                for node in ast.walk(tree):
                    if isinstance(node, ast.FunctionDef):
                        if hasattr(node, 'end_lineno') and hasattr(node, 'lineno'):
                            length = node.end_lineno - node.lineno
                            if length > 50:
                                smells.append({
                                    'type': 'Long Method',
                                    'severity': 'medium',
                                    'file': relative_path,
                                    'function': node.name,
                                    'line': node.lineno,
                                    'description': f'å‡½æ•°è¿‡é•¿ ({length} è¡Œ)',
                                    'suggestion': 'è€ƒè™‘å°†å‡½æ•°æ‹†åˆ†ä¸ºæ›´å°çš„å‡½æ•°'
                                })

                        # æ£€æµ‹å‚æ•°è¿‡å¤š
                        param_count = len(node.args.args)
                        if param_count > 5:
                            smells.append({
                                'type': 'Too Many Parameters',
                                'severity': 'low',
                                'file': relative_path,
                                'function': node.name,
                                'line': node.lineno,
                                'description': f'å‚æ•°è¿‡å¤š ({param_count} ä¸ª)',
                                'suggestion': 'è€ƒè™‘ä½¿ç”¨å‚æ•°å¯¹è±¡æˆ–é…ç½®ç±»'
                            })

                    # æ£€æµ‹å¤§ç±»
                    if isinstance(node, ast.ClassDef):
                        methods = [n for n in node.body if isinstance(n, ast.FunctionDef)]
                        if len(methods) > 20:
                            smells.append({
                                'type': 'Large Class',
                                'severity': 'high',
                                'file': relative_path,
                                'class': node.name,
                                'line': node.lineno,
                                'description': f'ç±»è¿‡å¤§ ({len(methods)} ä¸ªæ–¹æ³•)',
                                'suggestion': 'è€ƒè™‘æ‹†åˆ†ç±»æˆ–ä½¿ç”¨ç»„åˆæ¨¡å¼'
                            })

            except Exception:
                pass

        return smells

    def _build_import_graph(self, python_files: List[Path]) -> Dict[str, List[str]]:
        """æ„å»ºå¯¼å…¥ä¾èµ–å›¾"""
        import_graph = defaultdict(list)

        for file_path in python_files:
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()

                tree = ast.parse(content)
                relative_path = str(file_path.relative_to(self.project_path))

                for node in ast.walk(tree):
                    if isinstance(node, ast.Import):
                        for alias in node.names:
                            import_graph[relative_path].append(alias.name)
                    elif isinstance(node, ast.ImportFrom):
                        if node.module:
                            import_graph[relative_path].append(node.module)

            except Exception:
                pass

        return dict(import_graph)

    def _analyze_functions(self, python_files: List[Path]) -> Dict[str, Any]:
        """åˆ†æå‡½æ•°ç‰¹å¾"""
        analysis = {
            'total_functions': 0,
            'recursive_functions': [],
            'generator_functions': [],
            'async_functions': [],
            'decorators_used': defaultdict(int),
        }

        for file_path in python_files[:20]:
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()

                tree = ast.parse(content)
                relative_path = str(file_path.relative_to(self.project_path))

                for node in ast.walk(tree):
                    if isinstance(node, ast.FunctionDef):
                        analysis['total_functions'] += 1

                        # æ£€æµ‹é€’å½’
                        if self._is_recursive(node):
                            analysis['recursive_functions'].append({
                                'file': relative_path,
                                'function': node.name,
                                'line': node.lineno
                            })

                        # æ£€æµ‹ç”Ÿæˆå™¨
                        if any(isinstance(n, ast.Yield) for n in ast.walk(node)):
                            analysis['generator_functions'].append({
                                'file': relative_path,
                                'function': node.name,
                                'line': node.lineno
                            })

                        # æ£€æµ‹è£…é¥°å™¨
                        for decorator in node.decorator_list:
                            if isinstance(decorator, ast.Name):
                                analysis['decorators_used'][decorator.id] += 1

                    # æ£€æµ‹å¼‚æ­¥å‡½æ•°
                    if isinstance(node, ast.AsyncFunctionDef):
                        analysis['async_functions'].append({
                            'file': relative_path,
                            'function': node.name,
                            'line': node.lineno
                        })

            except Exception:
                pass

        analysis['decorators_used'] = dict(analysis['decorators_used'])
        return analysis

    def _is_recursive(self, func_node: ast.FunctionDef) -> bool:
        """æ£€æµ‹å‡½æ•°æ˜¯å¦é€’å½’"""
        func_name = func_node.name
        for node in ast.walk(func_node):
            if isinstance(node, ast.Call):
                if isinstance(node.func, ast.Name) and node.func.id == func_name:
                    return True
        return False

    def _analyze_class_hierarchy(self, python_files: List[Path]) -> Dict[str, Any]:
        """åˆ†æç±»ç»§æ‰¿å±‚æ¬¡"""
        hierarchy = {
            'total_classes': 0,
            'inheritance_depth': {},
            'abstract_classes': [],
            'dataclasses': [],
        }

        for file_path in python_files[:20]:
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()

                tree = ast.parse(content)
                relative_path = str(file_path.relative_to(self.project_path))

                for node in ast.walk(tree):
                    if isinstance(node, ast.ClassDef):
                        hierarchy['total_classes'] += 1

                        # æ£€æµ‹ç»§æ‰¿
                        if node.bases:
                            base_names = []
                            for base in node.bases:
                                if isinstance(base, ast.Name):
                                    base_names.append(base.id)
                            hierarchy['inheritance_depth'][node.name] = base_names

                        # æ£€æµ‹æŠ½è±¡ç±»
                        for decorator in node.decorator_list:
                            if isinstance(decorator, ast.Name):
                                if decorator.id in ['abstractmethod', 'ABC']:
                                    hierarchy['abstract_classes'].append({
                                        'file': relative_path,
                                        'class': node.name,
                                        'line': node.lineno
                                    })

                        # æ£€æµ‹ dataclass
                        for decorator in node.decorator_list:
                            if isinstance(decorator, ast.Name) and decorator.id == 'dataclass':
                                hierarchy['dataclasses'].append({
                                    'file': relative_path,
                                    'class': node.name,
                                    'line': node.lineno
                                })

            except Exception:
                pass

        return hierarchy

    def get_insights(self, category: str = 'all') -> Dict[str, Any]:
        """è·å–æ´å¯Ÿ"""
        if category == 'all':
            return self.insights
        return self.insights.get(category, {})

    def format_insights(self) -> str:
        """æ ¼å¼åŒ–æ´å¯Ÿä¸ºå¯è¯»æ–‡æœ¬"""
        output = []

        # æ¶æ„æ¨¡å¼
        output.append("ğŸ—ï¸  æ¶æ„æ¨¡å¼åˆ†æ")
        output.append("=" * 60)
        patterns = self.insights['architecture_patterns']
        if patterns['detected_patterns']:
            output.append("æ£€æµ‹åˆ°çš„æ¨¡å¼:")
            for pattern in patterns['detected_patterns']:
                output.append(f"  âœ“ {pattern}")
        else:
            output.append("  æœªæ£€æµ‹åˆ°æ˜æ˜¾çš„æ¶æ„æ¨¡å¼")
        output.append("")

        # ä»£ç å¼‚å‘³
        output.append("ğŸ‘ƒ ä»£ç å¼‚å‘³æ£€æµ‹")
        output.append("=" * 60)
        smells = self.insights['code_smells']
        if smells:
            output.append(f"å‘ç° {len(smells)} ä¸ªæ½œåœ¨é—®é¢˜:\n")
            for smell in smells[:10]:
                output.append(f"  [{smell['severity'].upper()}] {smell['type']}")
                output.append(f"  æ–‡ä»¶: {smell['file']}")
                output.append(f"  ä½ç½®: ç¬¬ {smell['line']} è¡Œ")
                output.append(f"  æè¿°: {smell['description']}")
                output.append(f"  å»ºè®®: {smell['suggestion']}")
                output.append("")
        else:
            output.append("  æœªå‘ç°æ˜æ˜¾çš„ä»£ç å¼‚å‘³")
        output.append("")

        # å‡½æ•°åˆ†æ
        output.append("âš™ï¸  å‡½æ•°ç‰¹å¾åˆ†æ")
        output.append("=" * 60)
        func_analysis = self.insights['function_analysis']
        output.append(f"æ€»å‡½æ•°æ•°: {func_analysis['total_functions']}")
        output.append(f"é€’å½’å‡½æ•°: {len(func_analysis['recursive_functions'])}")
        output.append(f"ç”Ÿæˆå™¨å‡½æ•°: {len(func_analysis['generator_functions'])}")
        output.append(f"å¼‚æ­¥å‡½æ•°: {len(func_analysis['async_functions'])}")

        if func_analysis['decorators_used']:
            output.append("\nå¸¸ç”¨è£…é¥°å™¨:")
            for decorator, count in sorted(
                func_analysis['decorators_used'].items(),
                key=lambda x: x[1],
                reverse=True
            )[:5]:
                output.append(f"  - @{decorator}: {count} æ¬¡")
        output.append("")

        # ç±»å±‚æ¬¡
        output.append("ğŸ›ï¸  ç±»å±‚æ¬¡åˆ†æ")
        output.append("=" * 60)
        class_hierarchy = self.insights['class_hierarchy']
        output.append(f"æ€»ç±»æ•°: {class_hierarchy['total_classes']}")
        output.append(f"æŠ½è±¡ç±»: {len(class_hierarchy['abstract_classes'])}")
        output.append(f"æ•°æ®ç±»: {len(class_hierarchy['dataclasses'])}")

        if class_hierarchy['inheritance_depth']:
            output.append(f"\nç»§æ‰¿å…³ç³»: {len(class_hierarchy['inheritance_depth'])} ä¸ªç±»æœ‰ç»§æ‰¿")

        return "\n".join(output)


def main():
    """ä¸»å‡½æ•°"""
    import argparse

    parser = argparse.ArgumentParser(
        description='AI é©±åŠ¨çš„æ™ºèƒ½ä»£ç æ´å¯Ÿ Skill'
    )

    parser.add_argument(
        'project_path',
        help='é¡¹ç›®è·¯å¾„'
    )

    parser.add_argument(
        '-c', '--category',
        choices=['all', 'architecture_patterns', 'code_smells', 'import_graph', 'function_analysis', 'class_hierarchy'],
        default='all',
        help='æ´å¯Ÿç±»åˆ«'
    )

    parser.add_argument(
        '--json',
        action='store_true',
        help='ä»¥ JSON æ ¼å¼è¾“å‡º'
    )

    args = parser.parse_args()

    # éªŒè¯é¡¹ç›®è·¯å¾„
    project_path = Path(args.project_path)
    if not project_path.exists():
        print(f"âŒ é”™è¯¯: é¡¹ç›®è·¯å¾„ä¸å­˜åœ¨: {project_path}")
        return 1

    # åˆå§‹åŒ– Skill
    skill = CodeInsightSkill(project_path)

    # è·å–æ´å¯Ÿ
    insights = skill.get_insights(args.category)

    if args.json:
        print(json.dumps(insights, indent=2, ensure_ascii=False))
    else:
        print(skill.format_insights())

    return 0


if __name__ == '__main__':
    sys.exit(main())
